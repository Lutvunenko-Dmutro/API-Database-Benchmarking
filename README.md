# API Database Benchmarking

Цей проект розроблений для вимірювання часу виконання SQL-запитів до бази даних при різних обсягах даних (1000, 10000, 100000, 1000000). Метою є тестування різних операцій: `SELECT`, `INSERT`, `UPDATE`, і `DELETE` на віддаленій базі даних.

## Вимоги до системи

- **Python 3.x**
- **psycopg2** (для підключення до PostgreSQL)
- **tabulate** (для виведення таблиці)
- Встановлений PostgreSQL сервер або підключення до віддаленого серверу (наприклад, через [Railway.app](https://railway.app)).

## Встановлення

1. **Клонування репозиторію:**

   Спочатку клонувати репозиторій:

   ```bash
   git clone https://github.com/your-username/API-DBBenchmarks.git
   cd API-DBBenchmarks
   ```

2. **Встановлення залежностей:**

   Використовуємо `pip` для встановлення всіх необхідних бібліотек:

   ```bash
   pip install -r requirements.txt
   ```

   Переконайтесь, що всі залежності коректно встановлені.

3. **Конфігурація підключення до бази даних:**

   У файлі `config.py` або через змінні середовища потрібно вказати правильні параметри для підключення до вашої віддаленої бази даних PostgreSQL.

   Приклад конфігурації:

   ```python
   DB_HOST = 'your-db-host'  # Наприклад, для Railway: dbxxxxxx.railway.app
   DB_PORT = '5432'  # Порт за замовчуванням для PostgreSQL
   DB_NAME = 'your-db-name'
   DB_USER = 'your-db-username'
   DB_PASSWORD = 'your-db-password'
   ```

4. **Ініціалізація бази даних:**

   Використовуйте SQL-скрипт або ручне вставлення для створення таблиці `items`, якщо вона ще не створена:

   ```sql
   CREATE TABLE items (
       id SERIAL PRIMARY KEY,
       name VARCHAR(100),
       description TEXT,
       price DECIMAL
   );
   ```

## Використання

1. **Запуск вимірювань часу для SQL запитів:**

   Для запуску скрипта, який виміряє час виконання різних SQL запитів (SELECT, INSERT, UPDATE, DELETE), скористайтеся наступною командою:

   ```bash
   python -m app.measure_queries
   ```

2. **Параметри запитів:**

   Скрипт виконуватиме замір часу для запитів на різних обсягах даних:
   - 1000
   - 10000
   - 100000
   - 1000000

   Для кожного обсягу даних будуть виміряні наступні операції:
   - **SELECT**: Вибірка 1000 записів
   - **INSERT**: Вставка записів в базу
   - **UPDATE**: Оновлення записів
   - **DELETE**: Видалення записів

3. **Виведення результатів:**

   Після виконання скрипта, результати будуть виведені в таблиці в консоль:

   ```plaintext
   +----------+----------------+----------------+----------------+----------------+
   | Records  | Select Time    | Insert Time    | Update Time    | Delete Time    |
   +----------+----------------+----------------+----------------+----------------+
   | 10       | 0.02s          | 0.05s          | 0.01s          | 0.03s          |
   | 100      | 0.10s          | 0.15s          | 0.05s          | 0.07s          |
   | 1000     | 0.50s          | 1.00s          | 0.20s          | 0.30s          |
   | 10000    | 2.00s          | 8.00s          | 1.50s          | 2.00s          |
   +----------+----------------+----------------+----------------+----------------+
   ```

   Час буде округлений до кількох десяткових знаків, щоб зручно порівнювати часи виконання для різних обсягів даних.

## Особливості проекту

- В даному проекті **не використовуються індекси**, щоб продемонструвати ефективність запитів без оптимізацій.
- Використовуються **паралельні запити** для операцій **UPDATE** та **DELETE**, щоб прискорити виконання запитів на великих наборах даних.

## Ресурси

- Для цього проекту використовується віддалена база даних PostgreSQL на платформі [Railway.app](https://railway.app), але ви можете підключити будь-який сервер PostgreSQL за вашими уподобаннями.
